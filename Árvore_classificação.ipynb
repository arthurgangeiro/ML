{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import   numpy  as   np \n",
    "import   pandas  as   pd \n",
    "from  sklearn . tree  import   DecisionTreeClassifier \n",
    "from  sklearn . metrics  import   accuracy_score \n",
    "from  sklearn  import   tree \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import LeaveOneOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('C:\\\\Users\\\\Fabiel Fernando\\\\Desktop\\\\PROVA\\\\classificacao_Q4.csv')\n",
    "X = dataset.iloc[:, 0:100].values\n",
    "y = np.array(dataset['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Porcentagem da variável resposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># target</th>\n",
       "      <th>% target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>153</td>\n",
       "      <td>10.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.0</th>\n",
       "      <td>153</td>\n",
       "      <td>10.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>152</td>\n",
       "      <td>10.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>150</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>150</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>149</td>\n",
       "      <td>9.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>149</td>\n",
       "      <td>9.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.0</th>\n",
       "      <td>149</td>\n",
       "      <td>9.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>148</td>\n",
       "      <td>9.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.0</th>\n",
       "      <td>147</td>\n",
       "      <td>9.800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     # target   % target\n",
       "2.0       153  10.200000\n",
       "8.0       153  10.200000\n",
       "3.0       152  10.133333\n",
       "0.0       150  10.000000\n",
       "4.0       150  10.000000\n",
       "1.0       149   9.933333\n",
       "6.0       149   9.933333\n",
       "9.0       149   9.933333\n",
       "5.0       148   9.866667\n",
       "7.0       147   9.800000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resposta = dataset['target']\n",
    "count = pd.DataFrame(resposta.value_counts())\n",
    "percent = pd.DataFrame(resposta.value_counts(normalize = True)*100)\n",
    "table = pd.concat([count, percent], axis = 1)\n",
    "table.columns = ['# target', '% target']\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treino e Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train ,  X_test ,  y_train ,  y_test  =  train_test_split (  X ,  y ,  test_size  =  0.3 ,  random_state  =  100 ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classificador de Árvore de Decisão com GINI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=5, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=100,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_gini = DecisionTreeClassifier(criterion = \"gini\", random_state = 100,\n",
    "                               max_depth=3, min_samples_leaf=5)\n",
    "clf_gini.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precisão do classificador da Árvore de Decisão com GINI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = clf_gini.predict(X_test)\n",
    "pred_train = clf_gini.predict(X_train)\n",
    "\n",
    "y_true = np.array(y_test.copy())\n",
    "y_pred = np.array(pred_test.copy())\n",
    "\n",
    "y_true_treino = np.array(y_train.copy())\n",
    "y_pred_treino = np.array(pred_train.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tabela com cálculo de vária métricas conjunto treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia para o treino é  0.44952380952380955\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.43      0.68      0.53       110\n",
      "        1.0       0.76      0.19      0.30       102\n",
      "        2.0       0.00      0.00      0.00       109\n",
      "        3.0       0.85      0.50      0.63       105\n",
      "        4.0       0.69      0.17      0.27       107\n",
      "        5.0       0.46      0.69      0.55       100\n",
      "        6.0       0.53      0.79      0.63       109\n",
      "        7.0       0.00      0.00      0.00       101\n",
      "        8.0       0.47      0.76      0.58        99\n",
      "        9.0       0.27      0.72      0.39       108\n",
      "\n",
      "avg / total       0.45      0.45      0.39      1050\n",
      " None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true_treino, y_pred_treino), \n",
    "    print (\"Acurácia para o treino é \", accuracy_score(y_true_treino,y_pred_treino)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tabela com cálculo de vária métricas conjunto teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia para o treino é  0.44\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.42      0.70      0.52        40\n",
      "        1.0       0.75      0.26      0.38        47\n",
      "        2.0       0.00      0.00      0.00        44\n",
      "        3.0       0.66      0.40      0.50        47\n",
      "        4.0       0.85      0.26      0.39        43\n",
      "        5.0       0.59      0.81      0.68        48\n",
      "        6.0       0.37      0.65      0.47        40\n",
      "        7.0       0.00      0.00      0.00        46\n",
      "        8.0       0.43      0.59      0.50        54\n",
      "        9.0       0.27      0.76      0.40        41\n",
      "\n",
      "avg / total       0.44      0.44      0.39       450\n",
      " None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, y_pred), \n",
    "    print (\"Acurácia para o treino é \", accuracy_score(y_true,y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classificador de Árvore de Decisão com ENTROPIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=3,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=5, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=100,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_entropy = DecisionTreeClassifier(criterion = \"entropy\", random_state = 100,\n",
    "                                     max_depth=3, min_samples_leaf=5)\n",
    "clf_entropy.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precisão do classificador da Árvore de Decisão com ENTROPIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = clf_entropy.predict(X_test)\n",
    "pred_train = clf_entropy.predict(X_train)\n",
    "\n",
    "y_true = np.array(y_test.copy())\n",
    "y_pred = np.array(pred_test.copy())\n",
    "\n",
    "y_true_treino = np.array(y_train.copy())\n",
    "y_pred_treino = np.array(pred_train.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tabela com cálculo de vária métricas conjunto treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia para o treino é  0.38285714285714284\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.47      0.74      0.57       110\n",
      "        1.0       0.28      0.67      0.40       102\n",
      "        2.0       0.00      0.00      0.00       109\n",
      "        3.0       0.00      0.00      0.00       105\n",
      "        4.0       0.46      0.23      0.31       107\n",
      "        5.0       0.00      0.00      0.00       100\n",
      "        6.0       0.40      0.81      0.53       109\n",
      "        7.0       0.35      0.75      0.48       101\n",
      "        8.0       0.00      0.00      0.00        99\n",
      "        9.0       0.44      0.59      0.51       108\n",
      "\n",
      "avg / total       0.24      0.38      0.28      1050\n",
      " None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true_treino, y_pred_treino), \n",
    "    print (\"Acurácia para o treino é \", accuracy_score(y_true_treino,y_pred_treino)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tabela com cálculo de vária métricas conjunto teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia para o treino é  0.32666666666666666\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.47      0.82      0.60        40\n",
      "        1.0       0.24      0.57      0.34        47\n",
      "        2.0       0.00      0.00      0.00        44\n",
      "        3.0       0.00      0.00      0.00        47\n",
      "        4.0       0.38      0.19      0.25        43\n",
      "        5.0       0.00      0.00      0.00        48\n",
      "        6.0       0.27      0.62      0.38        40\n",
      "        7.0       0.31      0.70      0.43        46\n",
      "        8.0       0.00      0.00      0.00        54\n",
      "        9.0       0.41      0.54      0.46        41\n",
      "\n",
      "avg / total       0.20      0.33      0.23       450\n",
      " None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, y_pred), \n",
    "    print (\"Acurácia para o treino é \", accuracy_score(y_true,y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ajustando o classificador com Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "cv_kfold = KFold(10, shuffle = False)\n",
    "param_grid = {'criterion':('gini', 'entropy'), \n",
    "              'min_samples_split':[2,3], \n",
    "              'max_depth':[9,10],\n",
    "              'class_weight':('balanced', None),\n",
    "              'presort':(False,True),\n",
    "             }\n",
    "cv_loo = LeaveOneOut()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_dt_cv = GridSearchCV(DecisionTreeClassifier(), param_grid, cv = cv_kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=10, random_state=None, shuffle=False),\n",
       "       error_score='raise',\n",
       "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'criterion': ('gini', 'entropy'), 'min_samples_split': [2, 3], 'max_depth': [9, 10], 'class_weight': ('balanced', None), 'presort': (False, True)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_dt_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight='balanced', criterion='gini',\n",
       "            max_depth=10, max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = clf_dt_cv.best_estimator_\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict, cross_val_score, GridSearchCV\n",
    "predicted = cross_val_score(model, X, y, cv = kfold, scoring = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia média é 0.5633333333333332\n"
     ]
    }
   ],
   "source": [
    "print (\"Acurácia média é\", predicted.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.47      0.82      0.60        40\n",
      "        1.0       0.24      0.57      0.34        47\n",
      "        2.0       0.00      0.00      0.00        44\n",
      "        3.0       0.00      0.00      0.00        47\n",
      "        4.0       0.38      0.19      0.25        43\n",
      "        5.0       0.00      0.00      0.00        48\n",
      "        6.0       0.27      0.62      0.38        40\n",
      "        7.0       0.31      0.70      0.43        46\n",
      "        8.0       0.00      0.00      0.00        54\n",
      "        9.0       0.41      0.54      0.46        41\n",
      "\n",
      "avg / total       0.20      0.33      0.23       450\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validação Cruzada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### k-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5393333333333334, 0.03869539162915054)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=42)\n",
    "model = DecisionTreeClassifier()\n",
    "scoring = 'accuracy'\n",
    "results = model_selection.cross_val_score(model, X, y, cv=kfold, scoring=scoring)\n",
    "results.mean(), results.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LOOCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5228571428571429"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DecisionTreeClassifier()\n",
    "accuracies = cross_val_score(model, X=X_train, y=y_train, cv=LeaveOneOut())\n",
    "accuracies.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Repeat CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5215873015873016"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_repeat = RepeatedKFold(n_splits=6, n_repeats=3, random_state=42)\n",
    "model = DecisionTreeClassifier()\n",
    "accuracies = cross_val_score(model, X=X_train, y=y_train, cv=cv_repeat)\n",
    "accuracies.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separando as k primeiras observações para treino e o restante para teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_treino = dataset.iloc[0:499, 0:99].values\n",
    "y_treino = dataset.iloc[0:499, 100].values\n",
    "\n",
    "\n",
    "X_teste = dataset.iloc[500:1500, 0:99].values\n",
    "y_teste = dataset.iloc[500:1500, 100].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterio = 'gini'\n",
    "#criterio = 'entropy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=5, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=100,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(criterion = criterio, random_state = 100,\n",
    "                                     max_depth=3, min_samples_leaf=5)\n",
    "clf.fit(X_treino, y_treino)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precisão do classificador da Árvore de Decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_teste = clf.predict(X_teste)\n",
    "pred_treino = clf.predict(X_treino)\n",
    "\n",
    "y_true = np.array(y_teste.copy())\n",
    "y_pred = np.array(pred_teste.copy())\n",
    "\n",
    "y_true_treino = np.array(y_treino.copy())\n",
    "y_pred_treino = np.array(pred_treino.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tabela com cálculo de vária métricas conjunto treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia para o treino é  0.46693386773547096\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.60      0.89      0.72        55\n",
      "        1.0       0.21      0.67      0.32        48\n",
      "        2.0       0.00      0.00      0.00        45\n",
      "        3.0       0.50      0.41      0.45        58\n",
      "        4.0       0.57      0.62      0.59        48\n",
      "        5.0       0.00      0.00      0.00        46\n",
      "        6.0       0.00      0.00      0.00        47\n",
      "        7.0       0.46      0.59      0.52        51\n",
      "        8.0       0.81      0.63      0.71        41\n",
      "        9.0       0.63      0.70      0.66        60\n",
      "\n",
      "avg / total       0.39      0.47      0.41       499\n",
      " None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true_treino, y_pred_treino), \n",
    "    print (\"Acurácia para o treino é \", accuracy_score(y_true_treino,y_pred_treino)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tabela com cálculo de vária métricas conjunto teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia para o treino é  0.364\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.49      0.88      0.63        95\n",
      "        1.0       0.20      0.72      0.31       101\n",
      "        2.0       0.00      0.00      0.00       108\n",
      "        3.0       0.41      0.28      0.33        94\n",
      "        4.0       0.52      0.45      0.48       102\n",
      "        5.0       0.00      0.00      0.00       102\n",
      "        6.0       0.00      0.00      0.00       102\n",
      "        7.0       0.36      0.46      0.41        96\n",
      "        8.0       0.74      0.33      0.46       111\n",
      "        9.0       0.41      0.61      0.49        89\n",
      "\n",
      "avg / total       0.31      0.36      0.30      1000\n",
      " None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_teste, y_pred), \n",
    "    print (\"Acurácia para o treino é \", accuracy_score(y_teste,y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
