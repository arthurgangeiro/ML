{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from  sklearn . tree  import   DecisionTreeClassifier \n",
    "from urllib.request import urlopen \n",
    "from sklearn.metrics  import   accuracy_score \n",
    "from sklearn import tree \n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "pd.set_option('display.max_columns', 500) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_teste(predictions, alg_name):\n",
    "\n",
    "    print('Resultados para o classificador {0}:'.format(alg_name))\n",
    "    print(classification_report(y_teste, predictions), \n",
    "    print (\"Acurácia para o treino é \", accuracy_score(y_teste,predictions)))\n",
    "    \n",
    "def report_treino(predictions, alg_name):\n",
    "\n",
    "    print('Resultados para o classificador {0}:'.format(alg_name))\n",
    "    print(classification_report(y_treino, predictions), \n",
    "    print (\"Acurácia para o treino é \", accuracy_score(y_treino,predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['x0', 'x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9', 'x10',\n",
       "       'x11', 'x12', 'x13', 'x14', 'x15', 'x16', 'x17', 'x18', 'x19', 'x20',\n",
       "       'x21', 'x22', 'x23', 'x24', 'x25', 'x26', 'x27', 'x28', 'x29', 'x30',\n",
       "       'x31', 'x32', 'x33', 'x34', 'x35', 'x36', 'x37', 'x38', 'x39', 'x40',\n",
       "       'x41', 'x42', 'x43', 'x44', 'x45', 'x46', 'x47', 'x48', 'x49', 'x50',\n",
       "       'x51', 'x52', 'x53', 'x54', 'x55', 'x56', 'x57', 'x58', 'x59', 'x60',\n",
       "       'x61', 'x62', 'x63', 'x64', 'x65', 'x66', 'x67', 'x68', 'x69', 'x70',\n",
       "       'x71', 'x72', 'x73', 'x74', 'x75', 'x76', 'x77', 'x78', 'x79', 'x80',\n",
       "       'x81', 'x82', 'x83', 'x84', 'x85', 'x86', 'x87', 'x88', 'x89', 'x90',\n",
       "       'x91', 'x92', 'x93', 'x94', 'x95', 'x96', 'x97', 'x98', 'x99'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('C:\\\\Users\\\\Fabiel Fernando\\\\Desktop\\\\PROVA\\\\classificacao_Q4.csv')\n",
    "dataset.columns\n",
    "names = dataset.columns\n",
    "names_index = names[0:100]\n",
    "names_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verificando a existência de missings\n",
    "#dataset.apply(lambda x: x.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>x11</th>\n",
       "      <th>x12</th>\n",
       "      <th>x13</th>\n",
       "      <th>x14</th>\n",
       "      <th>x15</th>\n",
       "      <th>x16</th>\n",
       "      <th>x17</th>\n",
       "      <th>x18</th>\n",
       "      <th>x19</th>\n",
       "      <th>x20</th>\n",
       "      <th>x21</th>\n",
       "      <th>x22</th>\n",
       "      <th>x23</th>\n",
       "      <th>x24</th>\n",
       "      <th>x25</th>\n",
       "      <th>x26</th>\n",
       "      <th>x27</th>\n",
       "      <th>x28</th>\n",
       "      <th>x29</th>\n",
       "      <th>x30</th>\n",
       "      <th>x31</th>\n",
       "      <th>x32</th>\n",
       "      <th>x33</th>\n",
       "      <th>x34</th>\n",
       "      <th>x35</th>\n",
       "      <th>x36</th>\n",
       "      <th>x37</th>\n",
       "      <th>x38</th>\n",
       "      <th>x39</th>\n",
       "      <th>x40</th>\n",
       "      <th>x41</th>\n",
       "      <th>x42</th>\n",
       "      <th>x43</th>\n",
       "      <th>x44</th>\n",
       "      <th>x45</th>\n",
       "      <th>x46</th>\n",
       "      <th>x47</th>\n",
       "      <th>x48</th>\n",
       "      <th>x49</th>\n",
       "      <th>x50</th>\n",
       "      <th>x51</th>\n",
       "      <th>x52</th>\n",
       "      <th>x53</th>\n",
       "      <th>x54</th>\n",
       "      <th>x55</th>\n",
       "      <th>x56</th>\n",
       "      <th>x57</th>\n",
       "      <th>x58</th>\n",
       "      <th>x59</th>\n",
       "      <th>x60</th>\n",
       "      <th>x61</th>\n",
       "      <th>x62</th>\n",
       "      <th>x63</th>\n",
       "      <th>x64</th>\n",
       "      <th>x65</th>\n",
       "      <th>x66</th>\n",
       "      <th>x67</th>\n",
       "      <th>x68</th>\n",
       "      <th>x69</th>\n",
       "      <th>x70</th>\n",
       "      <th>x71</th>\n",
       "      <th>x72</th>\n",
       "      <th>x73</th>\n",
       "      <th>x74</th>\n",
       "      <th>x75</th>\n",
       "      <th>x76</th>\n",
       "      <th>x77</th>\n",
       "      <th>x78</th>\n",
       "      <th>x79</th>\n",
       "      <th>x80</th>\n",
       "      <th>x81</th>\n",
       "      <th>x82</th>\n",
       "      <th>x83</th>\n",
       "      <th>x84</th>\n",
       "      <th>x85</th>\n",
       "      <th>x86</th>\n",
       "      <th>x87</th>\n",
       "      <th>x88</th>\n",
       "      <th>x89</th>\n",
       "      <th>x90</th>\n",
       "      <th>x91</th>\n",
       "      <th>x92</th>\n",
       "      <th>x93</th>\n",
       "      <th>x94</th>\n",
       "      <th>x95</th>\n",
       "      <th>x96</th>\n",
       "      <th>x97</th>\n",
       "      <th>x98</th>\n",
       "      <th>x99</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.696199</td>\n",
       "      <td>-0.792598</td>\n",
       "      <td>-0.349427</td>\n",
       "      <td>-0.464560</td>\n",
       "      <td>3.187014</td>\n",
       "      <td>0.035976</td>\n",
       "      <td>1.033274</td>\n",
       "      <td>-1.504968</td>\n",
       "      <td>0.204693</td>\n",
       "      <td>1.691204</td>\n",
       "      <td>-0.148668</td>\n",
       "      <td>-4.074097</td>\n",
       "      <td>-0.032896</td>\n",
       "      <td>-0.663494</td>\n",
       "      <td>-0.386016</td>\n",
       "      <td>-0.237805</td>\n",
       "      <td>-1.510523</td>\n",
       "      <td>-1.570864</td>\n",
       "      <td>-0.368605</td>\n",
       "      <td>0.812503</td>\n",
       "      <td>0.549905</td>\n",
       "      <td>-0.730260</td>\n",
       "      <td>0.761423</td>\n",
       "      <td>1.128273</td>\n",
       "      <td>-1.763750</td>\n",
       "      <td>0.579692</td>\n",
       "      <td>-0.293674</td>\n",
       "      <td>0.295500</td>\n",
       "      <td>-0.427231</td>\n",
       "      <td>-0.295434</td>\n",
       "      <td>-2.626552</td>\n",
       "      <td>-0.888908</td>\n",
       "      <td>0.360110</td>\n",
       "      <td>-3.085644</td>\n",
       "      <td>-0.945316</td>\n",
       "      <td>-0.904486</td>\n",
       "      <td>1.072223</td>\n",
       "      <td>1.778115</td>\n",
       "      <td>-0.148051</td>\n",
       "      <td>0.634574</td>\n",
       "      <td>0.209628</td>\n",
       "      <td>0.561244</td>\n",
       "      <td>-0.586968</td>\n",
       "      <td>-3.702351</td>\n",
       "      <td>-0.649087</td>\n",
       "      <td>0.066648</td>\n",
       "      <td>0.521637</td>\n",
       "      <td>-0.318873</td>\n",
       "      <td>-0.964632</td>\n",
       "      <td>-0.068293</td>\n",
       "      <td>-1.941717</td>\n",
       "      <td>0.011300</td>\n",
       "      <td>-0.030974</td>\n",
       "      <td>1.666534</td>\n",
       "      <td>1.907174</td>\n",
       "      <td>0.454065</td>\n",
       "      <td>0.157899</td>\n",
       "      <td>-1.415378</td>\n",
       "      <td>-0.220428</td>\n",
       "      <td>-1.163591</td>\n",
       "      <td>0.643701</td>\n",
       "      <td>-0.593975</td>\n",
       "      <td>-0.230020</td>\n",
       "      <td>2.142668</td>\n",
       "      <td>-1.150896</td>\n",
       "      <td>1.980677</td>\n",
       "      <td>1.115755</td>\n",
       "      <td>0.511176</td>\n",
       "      <td>-0.526043</td>\n",
       "      <td>-0.492225</td>\n",
       "      <td>1.291322</td>\n",
       "      <td>-0.795223</td>\n",
       "      <td>1.292448</td>\n",
       "      <td>0.804562</td>\n",
       "      <td>0.822480</td>\n",
       "      <td>-1.205006</td>\n",
       "      <td>-0.280887</td>\n",
       "      <td>-1.364098</td>\n",
       "      <td>0.312000</td>\n",
       "      <td>-1.925461</td>\n",
       "      <td>0.498012</td>\n",
       "      <td>0.371394</td>\n",
       "      <td>0.176175</td>\n",
       "      <td>0.547430</td>\n",
       "      <td>1.058247</td>\n",
       "      <td>0.503351</td>\n",
       "      <td>1.018997</td>\n",
       "      <td>0.221213</td>\n",
       "      <td>-0.419000</td>\n",
       "      <td>-0.858737</td>\n",
       "      <td>-0.534360</td>\n",
       "      <td>1.488142</td>\n",
       "      <td>-0.686337</td>\n",
       "      <td>2.084970</td>\n",
       "      <td>-0.685140</td>\n",
       "      <td>-2.049451</td>\n",
       "      <td>2.015426</td>\n",
       "      <td>1.158477</td>\n",
       "      <td>-0.309441</td>\n",
       "      <td>-1.549833</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.236696</td>\n",
       "      <td>-2.202342</td>\n",
       "      <td>0.024023</td>\n",
       "      <td>1.497700</td>\n",
       "      <td>-0.069758</td>\n",
       "      <td>-2.467088</td>\n",
       "      <td>1.126529</td>\n",
       "      <td>-0.570557</td>\n",
       "      <td>2.079251</td>\n",
       "      <td>-1.882632</td>\n",
       "      <td>-0.827576</td>\n",
       "      <td>1.005103</td>\n",
       "      <td>-0.137394</td>\n",
       "      <td>1.189628</td>\n",
       "      <td>-0.851586</td>\n",
       "      <td>-1.288871</td>\n",
       "      <td>-0.963559</td>\n",
       "      <td>1.227582</td>\n",
       "      <td>0.715197</td>\n",
       "      <td>0.520097</td>\n",
       "      <td>0.588903</td>\n",
       "      <td>-0.590111</td>\n",
       "      <td>-2.210356</td>\n",
       "      <td>1.022461</td>\n",
       "      <td>-1.039452</td>\n",
       "      <td>-0.241972</td>\n",
       "      <td>0.282824</td>\n",
       "      <td>0.001147</td>\n",
       "      <td>-1.621286</td>\n",
       "      <td>-1.815760</td>\n",
       "      <td>0.663234</td>\n",
       "      <td>-0.208910</td>\n",
       "      <td>0.113045</td>\n",
       "      <td>2.046566</td>\n",
       "      <td>0.761385</td>\n",
       "      <td>1.412045</td>\n",
       "      <td>2.094611</td>\n",
       "      <td>-0.286475</td>\n",
       "      <td>0.718189</td>\n",
       "      <td>-0.421027</td>\n",
       "      <td>1.182153</td>\n",
       "      <td>0.379603</td>\n",
       "      <td>-0.835262</td>\n",
       "      <td>0.937721</td>\n",
       "      <td>0.114378</td>\n",
       "      <td>-0.651730</td>\n",
       "      <td>-0.047160</td>\n",
       "      <td>3.589095</td>\n",
       "      <td>-0.486826</td>\n",
       "      <td>2.847869</td>\n",
       "      <td>0.162564</td>\n",
       "      <td>-0.039426</td>\n",
       "      <td>0.462479</td>\n",
       "      <td>-1.531158</td>\n",
       "      <td>-1.860289</td>\n",
       "      <td>0.455750</td>\n",
       "      <td>2.220489</td>\n",
       "      <td>1.212844</td>\n",
       "      <td>-1.329690</td>\n",
       "      <td>-1.452428</td>\n",
       "      <td>0.053086</td>\n",
       "      <td>-0.574263</td>\n",
       "      <td>-2.518650</td>\n",
       "      <td>-1.737640</td>\n",
       "      <td>-0.194589</td>\n",
       "      <td>0.648973</td>\n",
       "      <td>-0.342163</td>\n",
       "      <td>-0.508209</td>\n",
       "      <td>0.947281</td>\n",
       "      <td>-0.430554</td>\n",
       "      <td>0.661217</td>\n",
       "      <td>-1.936414</td>\n",
       "      <td>-1.698198</td>\n",
       "      <td>-3.313671</td>\n",
       "      <td>-0.183713</td>\n",
       "      <td>-0.549041</td>\n",
       "      <td>1.280620</td>\n",
       "      <td>2.177973</td>\n",
       "      <td>0.706155</td>\n",
       "      <td>-1.002186</td>\n",
       "      <td>-0.760492</td>\n",
       "      <td>0.390230</td>\n",
       "      <td>1.652978</td>\n",
       "      <td>-0.281058</td>\n",
       "      <td>-2.274763</td>\n",
       "      <td>-1.451749</td>\n",
       "      <td>-0.594344</td>\n",
       "      <td>1.292452</td>\n",
       "      <td>1.066120</td>\n",
       "      <td>0.036062</td>\n",
       "      <td>0.498207</td>\n",
       "      <td>0.405567</td>\n",
       "      <td>0.509564</td>\n",
       "      <td>1.374071</td>\n",
       "      <td>-0.016943</td>\n",
       "      <td>-0.429280</td>\n",
       "      <td>-0.895016</td>\n",
       "      <td>1.259566</td>\n",
       "      <td>-0.354139</td>\n",
       "      <td>0.806797</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.436683</td>\n",
       "      <td>1.563816</td>\n",
       "      <td>-0.895999</td>\n",
       "      <td>-0.580425</td>\n",
       "      <td>0.311060</td>\n",
       "      <td>-0.187369</td>\n",
       "      <td>0.805249</td>\n",
       "      <td>-2.399522</td>\n",
       "      <td>-0.578818</td>\n",
       "      <td>1.586981</td>\n",
       "      <td>-1.941955</td>\n",
       "      <td>-0.596377</td>\n",
       "      <td>-0.489321</td>\n",
       "      <td>-1.030148</td>\n",
       "      <td>-0.485569</td>\n",
       "      <td>0.902347</td>\n",
       "      <td>0.107147</td>\n",
       "      <td>-0.780838</td>\n",
       "      <td>0.402332</td>\n",
       "      <td>-1.450170</td>\n",
       "      <td>-0.583627</td>\n",
       "      <td>-0.706544</td>\n",
       "      <td>-0.025883</td>\n",
       "      <td>-1.450107</td>\n",
       "      <td>2.118729</td>\n",
       "      <td>1.015845</td>\n",
       "      <td>0.166787</td>\n",
       "      <td>-0.044010</td>\n",
       "      <td>-0.360155</td>\n",
       "      <td>0.101155</td>\n",
       "      <td>-0.799201</td>\n",
       "      <td>-1.102617</td>\n",
       "      <td>2.115397</td>\n",
       "      <td>-2.361777</td>\n",
       "      <td>0.525674</td>\n",
       "      <td>-1.911165</td>\n",
       "      <td>0.123961</td>\n",
       "      <td>-0.417771</td>\n",
       "      <td>0.548105</td>\n",
       "      <td>-0.217684</td>\n",
       "      <td>-0.431924</td>\n",
       "      <td>-0.442644</td>\n",
       "      <td>-1.489144</td>\n",
       "      <td>-1.000744</td>\n",
       "      <td>0.862522</td>\n",
       "      <td>-0.563455</td>\n",
       "      <td>0.588636</td>\n",
       "      <td>0.010576</td>\n",
       "      <td>-0.456408</td>\n",
       "      <td>-1.428348</td>\n",
       "      <td>0.216525</td>\n",
       "      <td>1.290350</td>\n",
       "      <td>-1.092070</td>\n",
       "      <td>0.522418</td>\n",
       "      <td>2.553921</td>\n",
       "      <td>0.087687</td>\n",
       "      <td>1.755408</td>\n",
       "      <td>-1.382265</td>\n",
       "      <td>0.032006</td>\n",
       "      <td>0.680842</td>\n",
       "      <td>0.911192</td>\n",
       "      <td>0.505370</td>\n",
       "      <td>-0.741637</td>\n",
       "      <td>0.980315</td>\n",
       "      <td>2.359120</td>\n",
       "      <td>-0.380329</td>\n",
       "      <td>0.234811</td>\n",
       "      <td>2.287361</td>\n",
       "      <td>-0.568738</td>\n",
       "      <td>-1.932310</td>\n",
       "      <td>-1.912456</td>\n",
       "      <td>-1.829811</td>\n",
       "      <td>-0.589138</td>\n",
       "      <td>0.473086</td>\n",
       "      <td>-0.237060</td>\n",
       "      <td>-0.106093</td>\n",
       "      <td>-0.690060</td>\n",
       "      <td>-0.640960</td>\n",
       "      <td>-1.088658</td>\n",
       "      <td>-0.998397</td>\n",
       "      <td>-1.579437</td>\n",
       "      <td>-0.697638</td>\n",
       "      <td>-0.620487</td>\n",
       "      <td>-0.320028</td>\n",
       "      <td>1.390414</td>\n",
       "      <td>0.449638</td>\n",
       "      <td>0.300941</td>\n",
       "      <td>-0.512526</td>\n",
       "      <td>0.656667</td>\n",
       "      <td>0.265771</td>\n",
       "      <td>-2.630024</td>\n",
       "      <td>0.933578</td>\n",
       "      <td>-1.285978</td>\n",
       "      <td>0.503162</td>\n",
       "      <td>0.204829</td>\n",
       "      <td>-0.753835</td>\n",
       "      <td>0.290033</td>\n",
       "      <td>1.721487</td>\n",
       "      <td>1.304518</td>\n",
       "      <td>0.478903</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.425908</td>\n",
       "      <td>0.400055</td>\n",
       "      <td>-0.305038</td>\n",
       "      <td>-0.930251</td>\n",
       "      <td>-2.214549</td>\n",
       "      <td>1.763379</td>\n",
       "      <td>-0.239868</td>\n",
       "      <td>-2.058891</td>\n",
       "      <td>-1.006533</td>\n",
       "      <td>-2.156839</td>\n",
       "      <td>-0.817310</td>\n",
       "      <td>3.135035</td>\n",
       "      <td>-1.046031</td>\n",
       "      <td>2.035231</td>\n",
       "      <td>0.307369</td>\n",
       "      <td>-0.831289</td>\n",
       "      <td>-0.263652</td>\n",
       "      <td>-1.479070</td>\n",
       "      <td>-0.675276</td>\n",
       "      <td>-0.222479</td>\n",
       "      <td>-0.441100</td>\n",
       "      <td>0.343649</td>\n",
       "      <td>0.210042</td>\n",
       "      <td>-2.030159</td>\n",
       "      <td>0.636847</td>\n",
       "      <td>-2.268783</td>\n",
       "      <td>1.066813</td>\n",
       "      <td>1.486655</td>\n",
       "      <td>0.665269</td>\n",
       "      <td>1.207031</td>\n",
       "      <td>3.549965</td>\n",
       "      <td>-0.026904</td>\n",
       "      <td>1.027441</td>\n",
       "      <td>1.979429</td>\n",
       "      <td>1.133188</td>\n",
       "      <td>1.709450</td>\n",
       "      <td>1.046510</td>\n",
       "      <td>1.397032</td>\n",
       "      <td>0.177327</td>\n",
       "      <td>-0.402179</td>\n",
       "      <td>-0.054244</td>\n",
       "      <td>-0.578126</td>\n",
       "      <td>-0.055127</td>\n",
       "      <td>2.794188</td>\n",
       "      <td>0.528181</td>\n",
       "      <td>-0.140851</td>\n",
       "      <td>-0.320488</td>\n",
       "      <td>-0.552952</td>\n",
       "      <td>-2.406692</td>\n",
       "      <td>0.054562</td>\n",
       "      <td>0.886823</td>\n",
       "      <td>-0.419061</td>\n",
       "      <td>-0.272393</td>\n",
       "      <td>-2.141239</td>\n",
       "      <td>-0.114749</td>\n",
       "      <td>0.230638</td>\n",
       "      <td>-0.250862</td>\n",
       "      <td>1.116209</td>\n",
       "      <td>1.452902</td>\n",
       "      <td>0.927677</td>\n",
       "      <td>-0.136729</td>\n",
       "      <td>-0.873607</td>\n",
       "      <td>0.430335</td>\n",
       "      <td>0.828970</td>\n",
       "      <td>0.313719</td>\n",
       "      <td>0.378332</td>\n",
       "      <td>-0.586515</td>\n",
       "      <td>-1.448876</td>\n",
       "      <td>-0.149765</td>\n",
       "      <td>-0.958114</td>\n",
       "      <td>-1.478115</td>\n",
       "      <td>-2.388252</td>\n",
       "      <td>-1.569214</td>\n",
       "      <td>-2.755844</td>\n",
       "      <td>-1.098166</td>\n",
       "      <td>1.450431</td>\n",
       "      <td>1.134263</td>\n",
       "      <td>2.586703</td>\n",
       "      <td>-0.224750</td>\n",
       "      <td>-0.036701</td>\n",
       "      <td>2.264622</td>\n",
       "      <td>-0.035200</td>\n",
       "      <td>0.217302</td>\n",
       "      <td>0.038805</td>\n",
       "      <td>-0.604043</td>\n",
       "      <td>-1.798876</td>\n",
       "      <td>-2.307973</td>\n",
       "      <td>1.441341</td>\n",
       "      <td>2.311820</td>\n",
       "      <td>-0.947016</td>\n",
       "      <td>-0.260665</td>\n",
       "      <td>-0.849927</td>\n",
       "      <td>1.402768</td>\n",
       "      <td>0.393653</td>\n",
       "      <td>-1.466818</td>\n",
       "      <td>0.152257</td>\n",
       "      <td>-4.004950</td>\n",
       "      <td>0.676342</td>\n",
       "      <td>-1.927319</td>\n",
       "      <td>1.959032</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.186156</td>\n",
       "      <td>-0.975764</td>\n",
       "      <td>0.594660</td>\n",
       "      <td>-1.181980</td>\n",
       "      <td>-1.443414</td>\n",
       "      <td>-0.797651</td>\n",
       "      <td>-1.252608</td>\n",
       "      <td>-0.060452</td>\n",
       "      <td>0.130702</td>\n",
       "      <td>-2.343517</td>\n",
       "      <td>0.892393</td>\n",
       "      <td>-0.533092</td>\n",
       "      <td>-0.760388</td>\n",
       "      <td>-0.702277</td>\n",
       "      <td>0.259456</td>\n",
       "      <td>3.732211</td>\n",
       "      <td>1.185647</td>\n",
       "      <td>2.046445</td>\n",
       "      <td>-1.378246</td>\n",
       "      <td>-0.733557</td>\n",
       "      <td>4.716702</td>\n",
       "      <td>0.229157</td>\n",
       "      <td>1.955133</td>\n",
       "      <td>1.917857</td>\n",
       "      <td>-1.783127</td>\n",
       "      <td>-0.839499</td>\n",
       "      <td>-1.811106</td>\n",
       "      <td>-0.405222</td>\n",
       "      <td>0.074332</td>\n",
       "      <td>2.034061</td>\n",
       "      <td>0.179220</td>\n",
       "      <td>-0.458617</td>\n",
       "      <td>-3.470883</td>\n",
       "      <td>0.561481</td>\n",
       "      <td>0.492969</td>\n",
       "      <td>1.310855</td>\n",
       "      <td>0.505790</td>\n",
       "      <td>-1.135986</td>\n",
       "      <td>-0.696156</td>\n",
       "      <td>0.815568</td>\n",
       "      <td>-0.266634</td>\n",
       "      <td>0.245124</td>\n",
       "      <td>1.244601</td>\n",
       "      <td>0.930504</td>\n",
       "      <td>-2.423524</td>\n",
       "      <td>-0.217978</td>\n",
       "      <td>-0.250712</td>\n",
       "      <td>-0.180181</td>\n",
       "      <td>1.579620</td>\n",
       "      <td>-1.239677</td>\n",
       "      <td>-0.917660</td>\n",
       "      <td>1.345773</td>\n",
       "      <td>0.545109</td>\n",
       "      <td>2.444263</td>\n",
       "      <td>-1.244190</td>\n",
       "      <td>0.446668</td>\n",
       "      <td>0.178714</td>\n",
       "      <td>-0.714363</td>\n",
       "      <td>0.310813</td>\n",
       "      <td>-4.723429</td>\n",
       "      <td>1.025380</td>\n",
       "      <td>0.567891</td>\n",
       "      <td>-1.215820</td>\n",
       "      <td>0.061255</td>\n",
       "      <td>1.798139</td>\n",
       "      <td>-0.254473</td>\n",
       "      <td>0.091907</td>\n",
       "      <td>0.680257</td>\n",
       "      <td>1.232538</td>\n",
       "      <td>-0.482364</td>\n",
       "      <td>1.012526</td>\n",
       "      <td>-0.554645</td>\n",
       "      <td>0.451229</td>\n",
       "      <td>0.484063</td>\n",
       "      <td>2.466720</td>\n",
       "      <td>0.102488</td>\n",
       "      <td>-0.574971</td>\n",
       "      <td>-2.885352</td>\n",
       "      <td>0.911710</td>\n",
       "      <td>-0.846603</td>\n",
       "      <td>0.850602</td>\n",
       "      <td>2.222440</td>\n",
       "      <td>-1.981894</td>\n",
       "      <td>0.156248</td>\n",
       "      <td>-2.788302</td>\n",
       "      <td>-0.067919</td>\n",
       "      <td>1.352606</td>\n",
       "      <td>-1.878879</td>\n",
       "      <td>-0.943184</td>\n",
       "      <td>-0.185896</td>\n",
       "      <td>1.098563</td>\n",
       "      <td>-1.444435</td>\n",
       "      <td>-1.818126</td>\n",
       "      <td>0.446574</td>\n",
       "      <td>0.239328</td>\n",
       "      <td>0.802939</td>\n",
       "      <td>-2.035289</td>\n",
       "      <td>-1.433793</td>\n",
       "      <td>-0.218596</td>\n",
       "      <td>0.619317</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         x0        x1        x2        x3        x4        x5        x6  \\\n",
       "0  1.696199 -0.792598 -0.349427 -0.464560  3.187014  0.035976  1.033274   \n",
       "1 -0.236696 -2.202342  0.024023  1.497700 -0.069758 -2.467088  1.126529   \n",
       "2 -0.436683  1.563816 -0.895999 -0.580425  0.311060 -0.187369  0.805249   \n",
       "3  1.425908  0.400055 -0.305038 -0.930251 -2.214549  1.763379 -0.239868   \n",
       "4 -0.186156 -0.975764  0.594660 -1.181980 -1.443414 -0.797651 -1.252608   \n",
       "\n",
       "         x7        x8        x9       x10       x11       x12       x13  \\\n",
       "0 -1.504968  0.204693  1.691204 -0.148668 -4.074097 -0.032896 -0.663494   \n",
       "1 -0.570557  2.079251 -1.882632 -0.827576  1.005103 -0.137394  1.189628   \n",
       "2 -2.399522 -0.578818  1.586981 -1.941955 -0.596377 -0.489321 -1.030148   \n",
       "3 -2.058891 -1.006533 -2.156839 -0.817310  3.135035 -1.046031  2.035231   \n",
       "4 -0.060452  0.130702 -2.343517  0.892393 -0.533092 -0.760388 -0.702277   \n",
       "\n",
       "        x14       x15       x16       x17       x18       x19       x20  \\\n",
       "0 -0.386016 -0.237805 -1.510523 -1.570864 -0.368605  0.812503  0.549905   \n",
       "1 -0.851586 -1.288871 -0.963559  1.227582  0.715197  0.520097  0.588903   \n",
       "2 -0.485569  0.902347  0.107147 -0.780838  0.402332 -1.450170 -0.583627   \n",
       "3  0.307369 -0.831289 -0.263652 -1.479070 -0.675276 -0.222479 -0.441100   \n",
       "4  0.259456  3.732211  1.185647  2.046445 -1.378246 -0.733557  4.716702   \n",
       "\n",
       "        x21       x22       x23       x24       x25       x26       x27  \\\n",
       "0 -0.730260  0.761423  1.128273 -1.763750  0.579692 -0.293674  0.295500   \n",
       "1 -0.590111 -2.210356  1.022461 -1.039452 -0.241972  0.282824  0.001147   \n",
       "2 -0.706544 -0.025883 -1.450107  2.118729  1.015845  0.166787 -0.044010   \n",
       "3  0.343649  0.210042 -2.030159  0.636847 -2.268783  1.066813  1.486655   \n",
       "4  0.229157  1.955133  1.917857 -1.783127 -0.839499 -1.811106 -0.405222   \n",
       "\n",
       "        x28       x29       x30       x31       x32       x33       x34  \\\n",
       "0 -0.427231 -0.295434 -2.626552 -0.888908  0.360110 -3.085644 -0.945316   \n",
       "1 -1.621286 -1.815760  0.663234 -0.208910  0.113045  2.046566  0.761385   \n",
       "2 -0.360155  0.101155 -0.799201 -1.102617  2.115397 -2.361777  0.525674   \n",
       "3  0.665269  1.207031  3.549965 -0.026904  1.027441  1.979429  1.133188   \n",
       "4  0.074332  2.034061  0.179220 -0.458617 -3.470883  0.561481  0.492969   \n",
       "\n",
       "        x35       x36       x37       x38       x39       x40       x41  \\\n",
       "0 -0.904486  1.072223  1.778115 -0.148051  0.634574  0.209628  0.561244   \n",
       "1  1.412045  2.094611 -0.286475  0.718189 -0.421027  1.182153  0.379603   \n",
       "2 -1.911165  0.123961 -0.417771  0.548105 -0.217684 -0.431924 -0.442644   \n",
       "3  1.709450  1.046510  1.397032  0.177327 -0.402179 -0.054244 -0.578126   \n",
       "4  1.310855  0.505790 -1.135986 -0.696156  0.815568 -0.266634  0.245124   \n",
       "\n",
       "        x42       x43       x44       x45       x46       x47       x48  \\\n",
       "0 -0.586968 -3.702351 -0.649087  0.066648  0.521637 -0.318873 -0.964632   \n",
       "1 -0.835262  0.937721  0.114378 -0.651730 -0.047160  3.589095 -0.486826   \n",
       "2 -1.489144 -1.000744  0.862522 -0.563455  0.588636  0.010576 -0.456408   \n",
       "3 -0.055127  2.794188  0.528181 -0.140851 -0.320488 -0.552952 -2.406692   \n",
       "4  1.244601  0.930504 -2.423524 -0.217978 -0.250712 -0.180181  1.579620   \n",
       "\n",
       "        x49       x50       x51       x52       x53       x54       x55  \\\n",
       "0 -0.068293 -1.941717  0.011300 -0.030974  1.666534  1.907174  0.454065   \n",
       "1  2.847869  0.162564 -0.039426  0.462479 -1.531158 -1.860289  0.455750   \n",
       "2 -1.428348  0.216525  1.290350 -1.092070  0.522418  2.553921  0.087687   \n",
       "3  0.054562  0.886823 -0.419061 -0.272393 -2.141239 -0.114749  0.230638   \n",
       "4 -1.239677 -0.917660  1.345773  0.545109  2.444263 -1.244190  0.446668   \n",
       "\n",
       "        x56       x57       x58       x59       x60       x61       x62  \\\n",
       "0  0.157899 -1.415378 -0.220428 -1.163591  0.643701 -0.593975 -0.230020   \n",
       "1  2.220489  1.212844 -1.329690 -1.452428  0.053086 -0.574263 -2.518650   \n",
       "2  1.755408 -1.382265  0.032006  0.680842  0.911192  0.505370 -0.741637   \n",
       "3 -0.250862  1.116209  1.452902  0.927677 -0.136729 -0.873607  0.430335   \n",
       "4  0.178714 -0.714363  0.310813 -4.723429  1.025380  0.567891 -1.215820   \n",
       "\n",
       "        x63       x64       x65       x66       x67       x68       x69  \\\n",
       "0  2.142668 -1.150896  1.980677  1.115755  0.511176 -0.526043 -0.492225   \n",
       "1 -1.737640 -0.194589  0.648973 -0.342163 -0.508209  0.947281 -0.430554   \n",
       "2  0.980315  2.359120 -0.380329  0.234811  2.287361 -0.568738 -1.932310   \n",
       "3  0.828970  0.313719  0.378332 -0.586515 -1.448876 -0.149765 -0.958114   \n",
       "4  0.061255  1.798139 -0.254473  0.091907  0.680257  1.232538 -0.482364   \n",
       "\n",
       "        x70       x71       x72       x73       x74       x75       x76  \\\n",
       "0  1.291322 -0.795223  1.292448  0.804562  0.822480 -1.205006 -0.280887   \n",
       "1  0.661217 -1.936414 -1.698198 -3.313671 -0.183713 -0.549041  1.280620   \n",
       "2 -1.912456 -1.829811 -0.589138  0.473086 -0.237060 -0.106093 -0.690060   \n",
       "3 -1.478115 -2.388252 -1.569214 -2.755844 -1.098166  1.450431  1.134263   \n",
       "4  1.012526 -0.554645  0.451229  0.484063  2.466720  0.102488 -0.574971   \n",
       "\n",
       "        x77       x78       x79       x80       x81       x82       x83  \\\n",
       "0 -1.364098  0.312000 -1.925461  0.498012  0.371394  0.176175  0.547430   \n",
       "1  2.177973  0.706155 -1.002186 -0.760492  0.390230  1.652978 -0.281058   \n",
       "2 -0.640960 -1.088658 -0.998397 -1.579437 -0.697638 -0.620487 -0.320028   \n",
       "3  2.586703 -0.224750 -0.036701  2.264622 -0.035200  0.217302  0.038805   \n",
       "4 -2.885352  0.911710 -0.846603  0.850602  2.222440 -1.981894  0.156248   \n",
       "\n",
       "        x84       x85       x86       x87       x88       x89       x90  \\\n",
       "0  1.058247  0.503351  1.018997  0.221213 -0.419000 -0.858737 -0.534360   \n",
       "1 -2.274763 -1.451749 -0.594344  1.292452  1.066120  0.036062  0.498207   \n",
       "2  1.390414  0.449638  0.300941 -0.512526  0.656667  0.265771 -2.630024   \n",
       "3 -0.604043 -1.798876 -2.307973  1.441341  2.311820 -0.947016 -0.260665   \n",
       "4 -2.788302 -0.067919  1.352606 -1.878879 -0.943184 -0.185896  1.098563   \n",
       "\n",
       "        x91       x92       x93       x94       x95       x96       x97  \\\n",
       "0  1.488142 -0.686337  2.084970 -0.685140 -2.049451  2.015426  1.158477   \n",
       "1  0.405567  0.509564  1.374071 -0.016943 -0.429280 -0.895016  1.259566   \n",
       "2  0.933578 -1.285978  0.503162  0.204829 -0.753835  0.290033  1.721487   \n",
       "3 -0.849927  1.402768  0.393653 -1.466818  0.152257 -4.004950  0.676342   \n",
       "4 -1.444435 -1.818126  0.446574  0.239328  0.802939 -2.035289 -1.433793   \n",
       "\n",
       "        x98       x99  target  \n",
       "0 -0.309441 -1.549833     4.0  \n",
       "1 -0.354139  0.806797     5.0  \n",
       "2  1.304518  0.478903     3.0  \n",
       "3 -1.927319  1.959032     8.0  \n",
       "4 -0.218596  0.619317     9.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensão dos nossos dados:\n",
      " (1500, 101)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dimensão dos nossos dados:\\n\", \n",
    "     dataset.shape)\n",
    "#print(\"Tipo de variáveis:\\n\",\n",
    "#     dataset.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pocentagem da variável resposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># target</th>\n",
       "      <th>% target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>153</td>\n",
       "      <td>10.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.0</th>\n",
       "      <td>153</td>\n",
       "      <td>10.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>152</td>\n",
       "      <td>10.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>150</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>150</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>149</td>\n",
       "      <td>9.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>149</td>\n",
       "      <td>9.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.0</th>\n",
       "      <td>149</td>\n",
       "      <td>9.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>148</td>\n",
       "      <td>9.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.0</th>\n",
       "      <td>147</td>\n",
       "      <td>9.800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     # target   % target\n",
       "2.0       153  10.200000\n",
       "8.0       153  10.200000\n",
       "3.0       152  10.133333\n",
       "0.0       150  10.000000\n",
       "4.0       150  10.000000\n",
       "1.0       149   9.933333\n",
       "6.0       149   9.933333\n",
       "9.0       149   9.933333\n",
       "5.0       148   9.866667\n",
       "7.0       147   9.800000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resposta = dataset['target']\n",
    "count = pd.DataFrame(resposta.value_counts())\n",
    "percent = pd.DataFrame(resposta.value_counts(normalize = True)*100)\n",
    "table = pd.concat([count, percent], axis = 1)\n",
    "table.columns = ['# target', '% target']\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Descritiva de algumas variáveis\n",
    "#dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treino e Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_space = dataset.iloc[:, dataset.columns != 'target']\n",
    "feature_class = dataset.iloc[:, dataset.columns == 'target']\n",
    "\n",
    "\n",
    "X_treino, X_teste, y_treino, y_teste = train_test_split(feature_space,\n",
    "                                                                    feature_class,\n",
    "                                                                    test_size = 0.30, \n",
    "                                                                    random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpar conjuntos de teste para evitar futuras mensagens de aviso\n",
    "y_treino = y_treino.values.ravel() \n",
    "y_teste = y_teste.values.ravel() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajustando Decission Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criterio = \"gini\"\n",
    "criterio = \"entropy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=3,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=5, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = DecisionTreeClassifier(criterion=criterio,\n",
    "                                    max_depth=3,\n",
    "                                    min_samples_leaf=5,\n",
    "                                    random_state=42,\n",
    "                                    max_leaf_nodes=None,\n",
    "                                    min_impurity_split=None,\n",
    "                                    class_weight=None,\n",
    "                                    presort=False)\n",
    "classifier.fit(X_treino, y_treino)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precisão do classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = classifier.predict(X_teste)\n",
    "pred_train = classifier.predict(X_treino)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tabela com cálculo de vária métricas conjunto treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados para o classificador Decision tree:\n",
      "Acurácia para o treino é  0.4123809523809524\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00       103\n",
      "        1.0       0.00      0.00      0.00        98\n",
      "        2.0       0.00      0.00      0.00       111\n",
      "        3.0       0.75      0.55      0.64       105\n",
      "        4.0       0.33      0.76      0.46       104\n",
      "        5.0       0.40      0.68      0.50        97\n",
      "        6.0       0.38      0.50      0.43        98\n",
      "        7.0       0.38      0.59      0.46       111\n",
      "        8.0       0.39      0.62      0.48       106\n",
      "        9.0       0.53      0.42      0.47       117\n",
      "\n",
      "avg / total       0.32      0.41      0.34      1050\n",
      " None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "report_treino(pred_train,'Decision tree')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tabela com cálculo de vária métricas conjunto teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados para o classificador Decision tree:\n",
      "Acurácia para o treino é  0.35555555555555557\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00        47\n",
      "        1.0       0.00      0.00      0.00        51\n",
      "        2.0       0.00      0.00      0.00        42\n",
      "        3.0       0.65      0.43      0.51        47\n",
      "        4.0       0.27      0.72      0.39        46\n",
      "        5.0       0.46      0.63      0.53        51\n",
      "        6.0       0.47      0.49      0.48        51\n",
      "        7.0       0.23      0.56      0.33        36\n",
      "        8.0       0.33      0.43      0.37        47\n",
      "        9.0       0.38      0.31      0.34        32\n",
      "\n",
      "avg / total       0.28      0.36      0.30       450\n",
      " None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "report_teste(pred_test,'Decision tree')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajustando o classificador com Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random state para reproducibilidade\n",
    "fit_dt = DecisionTreeClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "cv_kfold = KFold(10, shuffle = False)\n",
    "\n",
    "param_grid = {'criterion':('gini', 'entropy'), \n",
    "              'min_samples_split':[2,3], \n",
    "              'max_depth':[9,10],\n",
    "              'class_weight':('balanced', None),\n",
    "              'presort':(False,True),\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_dt = GridSearchCV(fit_dt,\n",
    "                     cv = cv_kfold,\n",
    "                     param_grid = param_grid, \n",
    "                     n_jobs = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=10, random_state=None, shuffle=False),\n",
       "       error_score='raise',\n",
       "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
       "            splitter='best'),\n",
       "       fit_params=None, iid=True, n_jobs=3,\n",
       "       param_grid={'criterion': ('gini', 'entropy'), 'min_samples_split': [2, 3], 'max_depth': [9, 10], 'class_weight': ('balanced', None), 'presort': (False, True)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_dt.fit(X_treino, y_treino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_weight': 'balanced',\n",
       " 'criterion': 'entropy',\n",
       " 'max_depth': 10,\n",
       " 'min_samples_split': 3,\n",
       " 'presort': False}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_dt.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight='balanced', criterion='entropy',\n",
       "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_dt.set_params(criterion = 'entropy',\n",
    "                  class_weight = 'balanced',\n",
    "                  max_features = 'auto', \n",
    "                  max_depth = 10,\n",
    "                  presort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight='balanced', criterion='entropy',\n",
       "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_dt.fit(X_treino, y_treino)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resultados Conjunto Treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados para o classificador Decision Tree com Grid Search:\n",
      "Acurácia para o treino é  0.9676190476190476\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      0.99      0.97       103\n",
      "        1.0       0.96      0.99      0.97        98\n",
      "        2.0       0.95      0.95      0.95       111\n",
      "        3.0       0.99      0.97      0.98       105\n",
      "        4.0       0.98      1.00      0.99       104\n",
      "        5.0       0.99      0.99      0.99        97\n",
      "        6.0       0.96      0.89      0.92        98\n",
      "        7.0       0.97      0.96      0.97       111\n",
      "        8.0       0.94      0.95      0.95       106\n",
      "        9.0       0.98      0.97      0.98       117\n",
      "\n",
      "avg / total       0.97      0.97      0.97      1050\n",
      " None\n"
     ]
    }
   ],
   "source": [
    "pred_train2 = fit_dt.predict(X_treino)\n",
    "report_treino(pred_train2, 'Decision Tree com Grid Search')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resultados conjunto teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados para o classificador Decision Tree com Grid Search:\n",
      "Acurácia para o treino é  0.4888888888888889\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.61      0.57      0.59        47\n",
      "        1.0       0.39      0.37      0.38        51\n",
      "        2.0       0.40      0.45      0.43        42\n",
      "        3.0       0.61      0.64      0.62        47\n",
      "        4.0       0.50      0.35      0.41        46\n",
      "        5.0       0.48      0.47      0.48        51\n",
      "        6.0       0.44      0.41      0.42        51\n",
      "        7.0       0.49      0.58      0.53        36\n",
      "        8.0       0.45      0.51      0.48        47\n",
      "        9.0       0.54      0.59      0.57        32\n",
      "\n",
      "avg / total       0.49      0.49      0.49       450\n",
      " None\n"
     ]
    }
   ],
   "source": [
    "predictions_fit_dt = fit_dt.predict(X_teste)\n",
    "report_teste(predictions_fit_dt, 'Decision Tree com Grid Search')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variáveis Importantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variable_importance(fit):\n",
    "    importances = fit.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    return {'importance': importances,\n",
    "            'index': indices}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_imp_dt = variable_importance(fit_dt)\n",
    "importances_dt = var_imp_dt['importance']\n",
    "indices_dt = var_imp_dt['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_var_importance(importance, indices, name_index):\n",
    "    print(\"Ranking das variáveis mais importantes:\")\n",
    "    for f in range(0, 5):\n",
    "        i = f\n",
    "        print(\"{0}. A variável '{1}' tem uma diminuição média na impureza de {2:.5f}\"\n",
    "              .format(f + 1,\n",
    "                      names_index[indices[i]],\n",
    "                      importance[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranking das variáveis mais importantes:\n",
      "1. A variável 'x53' tem uma diminuição média na impureza de 0.11414\n",
      "2. A variável 'x97' tem uma diminuição média na impureza de 0.08743\n",
      "3. A variável 'x41' tem uma diminuição média na impureza de 0.05727\n",
      "4. A variável 'x77' tem uma diminuição média na impureza de 0.04418\n",
      "5. A variável 'x1' tem uma diminuição média na impureza de 0.04006\n"
     ]
    }
   ],
   "source": [
    "print_var_importance(importances_dt, indices_dt, names_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_dt = fit_dt.predict(X_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[27  0  2  0  0  8  0  2  7  1]\n",
      " [ 0 19  2  4  4  2  8  3  6  3]\n",
      " [ 1  2 19  6  1  3  2  3  1  4]\n",
      " [ 0  5  1 30  1  0  1  4  1  4]\n",
      " [ 0 13  5  3 16  3  5  1  0  0]\n",
      " [ 6  5  4  2  0 24  5  0  1  4]\n",
      " [ 1  2  8  2  3  3 21  2  9  0]\n",
      " [ 4  2  0  1  0  3  1 21  4  0]\n",
      " [ 4  0  1  0  3  4  4  7 24  0]\n",
      " [ 1  1  5  1  4  0  1  0  0 19]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_teste, predictions_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aqui está a nossa precisão média no conjunto de testes: 0.489\n"
     ]
    }
   ],
   "source": [
    "accuracy_dt = fit_dt.score(X_teste, y_teste)\n",
    "\n",
    "print(\"Aqui está a nossa precisão média no conjunto de testes: {0:.3f}\".format(accuracy_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A taxa de erro de teste para o nosso modelo é:  0.511\n"
     ]
    }
   ],
   "source": [
    "test_error_rate_dt = 1 - accuracy_dt\n",
    "print(\"A taxa de erro de teste para o nosso modelo é: {0: .3f}\" .format(test_error_rate_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Curva ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_prob = fit_dt.predict_proba(X_teste)[:, 1]\n",
    "\n",
    "fpr2, tpr2, _ = roc_curve(y_teste,\n",
    "                          predictions_prob,\n",
    "                          pos_label = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_dt = auc(fpr2, tpr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr2, tpr2, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % auc_dt)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Taxa de Falso Positivo')\n",
    "plt.ylabel('Taxa de Verdadeiro Positivo')\n",
    "plt.title('Receiver operating characteristic ')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados para o classificador Decision Tree:\n",
      "Acurácia para o treino é  0.4888888888888889\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.61      0.57      0.59        47\n",
      "        1.0       0.39      0.37      0.38        51\n",
      "        2.0       0.40      0.45      0.43        42\n",
      "        3.0       0.61      0.64      0.62        47\n",
      "        4.0       0.50      0.35      0.41        46\n",
      "        5.0       0.48      0.47      0.48        51\n",
      "        6.0       0.44      0.41      0.42        51\n",
      "        7.0       0.49      0.58      0.53        36\n",
      "        8.0       0.45      0.51      0.48        47\n",
      "        9.0       0.54      0.59      0.57        32\n",
      "\n",
      "avg / total       0.49      0.49      0.49       450\n",
      " None\n"
     ]
    }
   ],
   "source": [
    "report_teste(predictions_dt, 'Decision Tree')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validação Cruzada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K - fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, 0:100].values\n",
    "y = dataset['target'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5353333333333332, 0.03155946767611901)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=42)\n",
    "model = DecisionTreeClassifier()\n",
    "scoring = 'accuracy'\n",
    "results = model_selection.cross_val_score(model, X, y, cv=kfold, scoring=scoring)\n",
    "results.mean(), results.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOOCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier()\n",
    "accuracies = cross_val_score(model, X=X, y=y, cv=LeaveOneOut())\n",
    "accuracies.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeat CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedKFold\n",
    "cv_repeat = RepeatedKFold(n_splits=6, n_repeats=3, random_state=42)\n",
    "model = DecisionTreeClassifier()\n",
    "accuracies = cross_val_score(model, X=X, y=y, cv=cv_repeat)\n",
    "accuracies.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separando as k primeiras observações para treino e o restante para teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_treino = dataset.iloc[0:499, 0:99].values\n",
    "y_treino = dataset.iloc[0:499, 100].values\n",
    "\n",
    "\n",
    "X_teste = dataset.iloc[500:1500, 0:99].values\n",
    "y_teste = dataset.iloc[500:1500, 100].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criterio = 'gini'\n",
    "criterio = 'entropy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(criterion=criterio,\n",
    "                                    max_depth=3,\n",
    "                                    min_samples_leaf=5,\n",
    "                                    random_state=42,\n",
    "                                    max_leaf_nodes=None,\n",
    "                                    min_impurity_split=None,\n",
    "                                    class_weight=None,\n",
    "                                    presort=False)\n",
    "clf.fit(X_treino, y_treino)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precisão do classificador no Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_teste = clf.predict(X_teste)\n",
    "pred_treino = clf.predict(X_treino)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Métricas Treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " report_treino(pred_treino, 'Decision Tree')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Métricas Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_teste(pred_teste, 'Decision Tree')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
